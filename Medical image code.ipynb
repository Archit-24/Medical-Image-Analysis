{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhe59wrkC0KZ",
        "outputId": "d3f98b9d-979e-4dd9-9c7e-412cc2240aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.8.2 in /usr/local/lib/python3.10/dist-packages (2.8.2)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (23.5.26)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (3.9.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.1.2)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (16.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (3.3.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.15.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (2.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (0.33.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.8.2) (1.57.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.8.2) (0.41.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.4.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.3.7)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=0.11.15->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow==2.8.2) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.8.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiPj6pAvtv6n",
        "outputId": "afa31685-93bf-410f-8b9e-d85803362977"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvu-ZWAl2mdk"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjQkwIyf2nMi"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0J2dV-seC-bR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation, add\n",
        "from keras.models import Model, model_from_json\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers.advanced_activations import ELU, LeakyReLU\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSbE1XTrDPXL",
        "outputId": "81420ad8-6185-4095-91bc-3cc98eca1a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "889\n",
            "889\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 889/889 [01:00<00:00, 14.64it/s]\n",
            "100%|██████████| 889/889 [00:11<00:00, 77.28it/s]\n"
          ]
        }
      ],
      "source": [
        "img_files = next(os.walk('/content/drive/MyDrive/ISBI2016_ISIC_Part1_Training_Data'))[2]\n",
        "msk_files = next(os.walk('/content/drive/MyDrive/ISBI2016_ISIC_Part1_Training_GroundTruth'))[2]\n",
        "\n",
        "img_files.sort()\n",
        "msk_files.sort()\n",
        "\n",
        "print(len(img_files))\n",
        "print(len(msk_files))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for img_fl in tqdm(img_files):\n",
        "    if(img_fl.split('.')[-1]=='jpg'):\n",
        "\n",
        "\n",
        "        img = cv2.imread('/content/drive/MyDrive/ISBI2016_ISIC_Part1_Training_Data/{}'.format(img_fl), cv2.IMREAD_COLOR)\n",
        "        resized_img = cv2.resize(img,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "        X.append(resized_img)\n",
        "\n",
        "for img_fl in tqdm(msk_files):\n",
        "   if(img_fl.split('.')[-1]=='png'):\n",
        "        msk = cv2.imread('/content/drive/MyDrive/ISBI2016_ISIC_Part1_Training_GroundTruth/{}'.format(img_fl.split('.')[0]+'.png'), cv2.IMREAD_GRAYSCALE)\n",
        "        resized_msk = cv2.resize(msk,(256, 192), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "        Y.append(resized_msk)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KC4ZfbyTDVyI",
        "outputId": "326a7120-1853-453f-b24e-85c10dd6b7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "889\n",
            "889\n",
            "(711, 192, 256, 3)\n",
            "(711, 192, 256, 1)\n",
            "(178, 192, 256, 3)\n",
            "(178, 192, 256, 1)\n"
          ]
        }
      ],
      "source": [
        "print(len(X))\n",
        "print(len(Y))\n",
        "\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=3)\n",
        "\n",
        "Y_train = Y_train.reshape((Y_train.shape[0],Y_train.shape[1],Y_train.shape[2],1))\n",
        "Y_test = Y_test.reshape((Y_test.shape[0],Y_test.shape[1],Y_test.shape[2],1))\n",
        "\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255\n",
        "Y_train = Y_train / 255\n",
        "Y_test = Y_test / 255\n",
        "\n",
        "Y_train = np.round(Y_train,0)\n",
        "Y_test = np.round(Y_test,0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V88WwzoqDcOM"
      },
      "outputs": [],
      "source": [
        "def conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(1, 1), activation='relu', name=None):\n",
        "    '''\n",
        "    2D Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(1, 1)})\n",
        "        activation {str} -- activation function (default: {'relu'})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    if(activation == None):\n",
        "        return x\n",
        "\n",
        "    x = Activation(activation, name=name)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def trans_conv2d_bn(x, filters, num_row, num_col, padding='same', strides=(2, 2), name=None):\n",
        "    '''\n",
        "    2D Transposed Convolutional layers\n",
        "\n",
        "    Arguments:\n",
        "        x {keras layer} -- input layer\n",
        "        filters {int} -- number of filters\n",
        "        num_row {int} -- number of rows in filters\n",
        "        num_col {int} -- number of columns in filters\n",
        "\n",
        "    Keyword Arguments:\n",
        "        padding {str} -- mode of padding (default: {'same'})\n",
        "        strides {tuple} -- stride of convolution operation (default: {(2, 2)})\n",
        "        name {str} -- name of the layer (default: {None})\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    x = Conv2DTranspose(filters, (num_row, num_col), strides=strides, padding=padding)(x)\n",
        "    x = BatchNormalization(axis=3, scale=False)(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def MultiResBlock(U, inp, alpha = 1.67):\n",
        "    '''\n",
        "    MultiRes Block\n",
        "\n",
        "    Arguments:\n",
        "        U {int} -- Number of filters in a corrsponding UNet stage\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "    W = alpha * U\n",
        "\n",
        "    shortcut = inp\n",
        "\n",
        "    shortcut = conv2d_bn(shortcut, int(W*0.167) + int(W*0.333) +\n",
        "                         int(W*0.5), 1, 1, activation=None, padding='same')\n",
        "\n",
        "    conv3x3 = conv2d_bn(inp, int(W*0.167), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv5x5 = conv2d_bn(conv3x3, int(W*0.333), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    conv7x7 = conv2d_bn(conv5x5, int(W*0.5), 3, 3,\n",
        "                        activation='relu', padding='same')\n",
        "\n",
        "    out = concatenate([conv3x3, conv5x5, conv7x7], axis=3)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def ResPath(filters, length, inp):\n",
        "    '''\n",
        "    ResPath\n",
        "\n",
        "    Arguments:\n",
        "        filters {int} -- [description]\n",
        "        length {int} -- length of ResPath\n",
        "        inp {keras layer} -- input layer\n",
        "\n",
        "    Returns:\n",
        "        [keras layer] -- [output layer]\n",
        "    '''\n",
        "\n",
        "\n",
        "    shortcut = inp\n",
        "    shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                         activation=None, padding='same')\n",
        "\n",
        "    out = conv2d_bn(inp, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "    out = add([shortcut, out])\n",
        "    out = Activation('relu')(out)\n",
        "    out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    for i in range(length-1):\n",
        "\n",
        "        shortcut = out\n",
        "        shortcut = conv2d_bn(shortcut, filters, 1, 1,\n",
        "                             activation=None, padding='same')\n",
        "\n",
        "        out = conv2d_bn(out, filters, 3, 3, activation='relu', padding='same')\n",
        "\n",
        "        out = add([shortcut, out])\n",
        "        out = Activation('relu')(out)\n",
        "        out = BatchNormalization(axis=3)(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "def MultiResUnet(height, width, n_channels):\n",
        "    '''\n",
        "    MultiResUNet\n",
        "\n",
        "    Arguments:\n",
        "        height {int} -- height of image\n",
        "        width {int} -- width of image\n",
        "        n_channels {int} -- number of channels in image\n",
        "\n",
        "    Returns:\n",
        "        [keras model] -- MultiResUNet model\n",
        "    '''\n",
        "\n",
        "\n",
        "    inputs = Input((height, width, n_channels))\n",
        "\n",
        "    mresblock1 = MultiResBlock(32, inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(mresblock1)\n",
        "    mresblock1 = ResPath(32, 4, mresblock1)\n",
        "\n",
        "    mresblock2 = MultiResBlock(32*2, pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(mresblock2)\n",
        "    mresblock2 = ResPath(32*2, 3, mresblock2)\n",
        "\n",
        "    mresblock3 = MultiResBlock(32*4, pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(mresblock3)\n",
        "    mresblock3 = ResPath(32*4, 2, mresblock3)\n",
        "\n",
        "    mresblock4 = MultiResBlock(32*8, pool3)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(mresblock4)\n",
        "    mresblock4 = ResPath(32*8, 1, mresblock4)\n",
        "\n",
        "    mresblock5 = MultiResBlock(32*16, pool4)\n",
        "\n",
        "    up6 = concatenate([Conv2DTranspose(\n",
        "        32*8, (2, 2), strides=(2, 2), padding='same')(mresblock5), mresblock4], axis=3)\n",
        "    mresblock6 = MultiResBlock(32*8, up6)\n",
        "\n",
        "    up7 = concatenate([Conv2DTranspose(\n",
        "        32*4, (2, 2), strides=(2, 2), padding='same')(mresblock6), mresblock3], axis=3)\n",
        "    mresblock7 = MultiResBlock(32*4, up7)\n",
        "\n",
        "    up8 = concatenate([Conv2DTranspose(\n",
        "        32*2, (2, 2), strides=(2, 2), padding='same')(mresblock7), mresblock2], axis=3)\n",
        "    mresblock8 = MultiResBlock(32*2, up8)\n",
        "\n",
        "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(\n",
        "        2, 2), padding='same')(mresblock8), mresblock1], axis=3)\n",
        "    mresblock9 = MultiResBlock(32, up9)\n",
        "\n",
        "    conv10 = conv2d_bn(mresblock9, 1, 1, 1, activation='sigmoid')\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_M8o1hD-Dqg0"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 0.0\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def jacard(y_true, y_pred):\n",
        "\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum ( y_true_f * y_pred_f)\n",
        "    union = K.sum ( y_true_f + y_pred_f - y_true_f * y_pred_f)\n",
        "\n",
        "    return intersection/union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSqywdBlDxZU"
      },
      "outputs": [],
      "source": [
        "def saveModel(model):\n",
        "\n",
        "    model_json = model.to_json()\n",
        "\n",
        "    try:\n",
        "        os.makedirs('models')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    fp = open('models/modelP.json','w')\n",
        "    fp.write(model_json)\n",
        "    model.save_weights('models/modelW.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J3GiQOyDDiB_"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_circles\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE82hHJeD3vV"
      },
      "outputs": [],
      "source": [
        "def evaluateModel(model, X_test, Y_test, batchSize):\n",
        "\n",
        "    try:\n",
        "        os.makedirs('results')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "\n",
        "    yp = model.predict(x=X_test, batch_size=batchSize, verbose=1)\n",
        "\n",
        "    yp = np.round(yp,0)\n",
        "\n",
        "    for i in range(10):\n",
        "\n",
        "        plt.figure(figsize=(20,10))\n",
        "        plt.subplot(1,3,1)\n",
        "        plt.imshow(X_test[i])\n",
        "        plt.title('Input')\n",
        "        plt.subplot(1,3,2)\n",
        "        plt.imshow(Y_test[i].reshape(Y_test[i].shape[0],Y_test[i].shape[1]))\n",
        "        plt.title('Ground Truth')\n",
        "        plt.subplot(1,3,3)\n",
        "        plt.imshow(yp[i].reshape(yp[i].shape[0],yp[i].shape[1]))\n",
        "        plt.title('Prediction')\n",
        "\n",
        "        intersection = yp[i].ravel() * Y_test[i].ravel()\n",
        "        union = yp[i].ravel() + Y_test[i].ravel() - intersection\n",
        "\n",
        "        jacard = (np.sum(intersection)/np.sum(union))\n",
        "        plt.suptitle('Jacard Index'+ str(np.sum(intersection)) +'/'+ str(np.sum(union)) +'='+str(jacard))\n",
        "\n",
        "        plt.savefig('//content/drive/MyDrive/results/'+str(i)+'.png',format='png')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "    jacard = 0\n",
        "    dice = 0\n",
        "    precision=0\n",
        "    recall=0\n",
        "\n",
        "\n",
        "    for i in range(len(Y_test)):\n",
        "        yp_2 = yp[i].ravel()\n",
        "        y2 = Y_test[i].ravel()\n",
        "\n",
        "        intersection = yp_2 * y2\n",
        "        union = yp_2 + y2 - intersection\n",
        "\n",
        "        jacard += (np.sum(intersection)/np.sum(union))\n",
        "\n",
        "        dice += (2. * np.sum(intersection) ) / (np.sum(yp_2) + np.sum(y2))\n",
        "        precision += precision_score(yp_2, y2)\n",
        "        recall += recall_score(yp_2, y2)\n",
        "\n",
        "    jacard /= len(Y_test)\n",
        "    dice /= len(Y_test)\n",
        "    precision /=len(Y_test)\n",
        "    recall /= len(Y_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print('Jacard Index : '+str(jacard))\n",
        "    print('Dice Coefficient : '+str(dice))\n",
        "    print('Precision : ' +str(precision))\n",
        "    print('Recall  : '+str(recall))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    fp = open('/content/drive/MyDrive/models/log.txt','a')\n",
        "    fp.write(str(jacard)+'\\n')\n",
        "    fp.close()\n",
        "\n",
        "    fp = open('/content/drive/MyDrive/models/best.txt','r')\n",
        "    best = fp.read()\n",
        "    fp.close()\n",
        "\n",
        "    if(jacard>float(best)):\n",
        "        print('***********************************************')\n",
        "        print('Jacard Index improved from '+str(best)+' to '+str(jacard))\n",
        "        print('***********************************************')\n",
        "        fp = open('/content/drive/MyDrive/models/best.txt','w')\n",
        "        fp.write(str(jacard))\n",
        "        fp.close()\n",
        "\n",
        "        saveModel(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLpmDzxhECfB"
      },
      "outputs": [],
      "source": [
        "def trainStep(model, X_train, Y_train, X_test, Y_test, epochs, batchSize):\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        print('Epoch : {}'.format(epoch+1))\n",
        "        model.fit(x=X_train, y=Y_train, batch_size=batchSize, epochs=1, verbose=1)\n",
        "\n",
        "        evaluateModel(model,X_test, Y_test,batchSize)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc-9AsnhEIYI",
        "outputId": "17b84113-8214-41fe-e8b5-1ae57ae66a63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 1\n",
            "72/72 [==============================] - 60s 478ms/step - loss: 0.5560 - dice_coef: 0.4650 - jacard: 0.3054 - accuracy: 0.7661\n",
            "18/18 [==============================] - 7s 258ms/step\n",
            "Jacard Index : 0.28991322035200134\n",
            "Dice Coefficient : 0.4095115145459199\n",
            "Precision : 1.0\n",
            "Recall  : 0.28991322035200134\n",
            "***********************************************\n",
            "Jacard Index improved from -1.0 to 0.28991322035200134\n",
            "***********************************************\n",
            "Epoch : 2\n",
            "72/72 [==============================] - 30s 419ms/step - loss: 0.5046 - dice_coef: 0.4833 - jacard: 0.3214 - accuracy: 0.8198\n",
            "18/18 [==============================] - 2s 109ms/step\n",
            "Jacard Index : 0.30959520346224606\n",
            "Dice Coefficient : 0.43164324302120727\n",
            "Precision : 0.9959871339327122\n",
            "Recall  : 0.31231411123682606\n",
            "***********************************************\n",
            "Jacard Index improved from 0.28991322035200134 to 0.30959520346224606\n",
            "***********************************************\n",
            "Epoch : 3\n",
            "72/72 [==============================] - 31s 436ms/step - loss: 0.4854 - dice_coef: 0.4867 - jacard: 0.3246 - accuracy: 0.8350\n",
            "18/18 [==============================] - 2s 112ms/step\n",
            "Jacard Index : 0.4007805048493585\n",
            "Dice Coefficient : 0.5377598126200535\n",
            "Precision : 0.9320739621382548\n",
            "Recall  : 0.4449924100461018\n",
            "***********************************************\n",
            "Jacard Index improved from 0.30959520346224606 to 0.4007805048493585\n",
            "***********************************************\n",
            "Epoch : 4\n",
            "72/72 [==============================] - 31s 437ms/step - loss: 0.4754 - dice_coef: 0.4904 - jacard: 0.3268 - accuracy: 0.8369\n",
            "18/18 [==============================] - 2s 111ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacard Index : 0.33936534554358044\n",
            "Dice Coefficient : 0.4550084205582624\n",
            "Precision : 0.48064959004834357\n",
            "Recall  : 0.6839419460503111\n",
            "Epoch : 5\n",
            "72/72 [==============================] - 32s 437ms/step - loss: 0.4608 - dice_coef: 0.4938 - jacard: 0.3297 - accuracy: 0.8443\n",
            "18/18 [==============================] - 2s 111ms/step\n",
            "Jacard Index : 0.415185550786989\n",
            "Dice Coefficient : 0.5502125576813834\n",
            "Precision : 0.9561863097746506\n",
            "Recall  : 0.4456605520915638\n",
            "***********************************************\n",
            "Jacard Index improved from 0.4007805048493585 to 0.415185550786989\n",
            "***********************************************\n",
            "Epoch : 6\n",
            "72/72 [==============================] - 32s 437ms/step - loss: 0.4514 - dice_coef: 0.4952 - jacard: 0.3312 - accuracy: 0.8467\n",
            "18/18 [==============================] - 2s 115ms/step\n",
            "Jacard Index : 0.5035721635156407\n",
            "Dice Coefficient : 0.6398616671928709\n",
            "Precision : 0.8863079376708923\n",
            "Recall  : 0.5950639748095408\n",
            "***********************************************\n",
            "Jacard Index improved from 0.415185550786989 to 0.5035721635156407\n",
            "***********************************************\n",
            "Epoch : 7\n",
            "72/72 [==============================] - 32s 439ms/step - loss: 0.4410 - dice_coef: 0.5020 - jacard: 0.3363 - accuracy: 0.8502\n",
            "18/18 [==============================] - 2s 114ms/step\n",
            "Jacard Index : 0.5446316695427657\n",
            "Dice Coefficient : 0.6741777673705418\n",
            "Precision : 0.807797111941719\n",
            "Recall  : 0.6959614875830558\n",
            "***********************************************\n",
            "Jacard Index improved from 0.5035721635156407 to 0.5446316695427657\n",
            "***********************************************\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.functional.Functional at 0x7a924d9d9ba0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model = MultiResUnet(height=192, width=256, n_channels=3)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
        "\n",
        "model.save('model')\n",
        "\n",
        "fp = open('/content/drive/MyDrive/models/log.txt','w')\n",
        "fp.close()\n",
        "fp = open('/content/drive/MyDrive/models/best.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()\n",
        "\n",
        "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=7, batchSize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPRZ7AWDVxhu"
      },
      "source": [
        "# New Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MiXO2DujO84g"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "py_file_location = \"/content/drive/MyDrive/\"\n",
        "sys.path.append(os.path.abspath(py_file_location))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK-tH982pjdo",
        "outputId": "d3fcd913-0eb5-41bf-9eaa-d228723363fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting segmed\n",
            "  Downloading segmed-0.6.12-py3-none-any.whl (22 kB)\n",
            "Collecting scikit-image<0.17.0,>=0.16.2 (from segmed)\n",
            "  Downloading scikit-image-0.16.2.tar.gz (28.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.9/28.9 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install segmed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxR_0QhLN8Lj"
      },
      "outputs": [],
      "source": [
        "from MultiResUNet import MultiResUnet\n",
        "\n",
        "model = MultiResUnet(height=192, width=256, n_channels=3)\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[dice_coef, jacard, 'accuracy'])\n",
        "\n",
        "model.save('model')\n",
        "\n",
        "fp = open('/content/drive/MyDrive/models/lognew.txt','w')\n",
        "fp.close()\n",
        "fp = open('/content/drive/MyDrive/models/bestnew.txt','w')\n",
        "fp.write('-1.0')\n",
        "fp.close()\n",
        "\n",
        "trainStep(model, X_train, Y_train, X_test, Y_test, epochs=7, batchSize=10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}